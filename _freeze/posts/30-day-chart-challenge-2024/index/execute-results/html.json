{
  "hash": "f55ee16ae984d2ebb1e2c9c1aa18a27e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"30 Day Chart Challenge 2024\"\ndescription: \"Let's make some charts!\"\nauthor: \"gregers kjerulf dubrow\"\ndate: \"today\"\ncategories: [post, rstats, ggplot, dataviz, chartchallenge, tidytuesday, eurostat]\nimage: \"prompts.png\"\ntoc: true\nlightbox: true\neditor: \n  mode: source\n---\n\n\n\n\n![](prompts.png){width=\"75%\" fig-align=\"left\" fig-alt=\"image listing the prompts for the 30 day chart challenge 2024.\"}\n\n## My Plan for the Challenge {#plan}\n\nIf you regularly scroll through dataviz social media you probably see lots of posts in April where people show off their work for the [30 Day Chart Challenge](https://github.com/30DayChartChallenge/Edition2024). I never participate in these chart or map challenges because usually they take me by surprise and it's alreayd a week in before I notice and then I figure I'm too late.\n\nWell not this year. Even though I'm (checks calendar) *three weeks* late to the party, I'm going to try and add a few charts to the challenge. I figure it's a good way to keep me consistently creating new visualisations, using the prompts to spur me to think about different data sources and dataviz approaches. My plan is to:\n\n-   Produce charts for as many prompts as possible, working in prompt-day order.\n-   Post them to social media on my [Bluesky](https://bsky.app/profile/gregerskjerulf.bsky.social), [Mastodon](https://fosstodon.org/@Greg_Dubrow), [Twitter](https://twitter.com/greg_dubrow), and [LinkedIn](https://www.linkedin.com/in/dubrowg/) accounts.\n-   Add them to this post, meaning the posting date will refresh to the date I've added the chart.So If I get to alot or even all of them, this will be a long post.\n-   Use the table of contents to the right to navigate to a specific chart.\n\nI may not get to every prompt, but I'll do what I can. So let's get going.\n\n## Prompt #1 - Part-to-Whole {#prompt1}\n\nI chose to interpret this prompt by doing a stacked bar chart displaying educational attainment as a proportion of populations by regions in the UK. It doubles as a late-to-the-party entry for the [January 23, 2024 Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2024/2024-01-23) challenge.\n\nThe original data is from the UK Office of National Statistics, in a report they produced looking at [educational attainment by socio-economic factors](https://www.ons.gov.uk/peoplepopulationandcommunity/educationandchildcare/articles/whydochildrenandyoungpeopleinsmallertownsdobetteracademicallythanthoseinlargertowns/2023-07-25).\n\nMy plan for this was to knock out the chart in about an hour, but I needed up having to do a bit more data transformation than I thought. I also had to read up a bit on UK education [levels](https://www.gov.uk/what-different-qualification-levels-mean/list-of-qualification-levels) and [stages](https://www.gov.uk/national-curriculum). In the end, it took a few hours to get it as I wanted.\n\nFirst we'll get and clean the data...\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting and cleaning data\"}\nlibrary(tidyverse) # to do tidyverse things\nlibrary(tidytuesdayR) #to get data from tidy tuesday repo\nlibrary(tidylog) # to get a log of what's happening to the data\nlibrary(janitor) # tools for data cleaning\nlibrary(ggtext) # to help make ggplot text look good\n\n# load tidy tuesday data\nukeduc1 <- tt_load(\"2024-01-23\")\n#> \n#> \tDownloading file 1 of 1: `english_education.csv`\n\n# create tibble from csv, clean data, add some fields for the chart\nukeduc <- as_tibble(ukeduc1$english_education) %>%\n\tmutate(town11nm = ifelse(town11nm == \"Outer london BUAs\", \"Outer London BUAs\", town11nm)) %>%\n\tmutate(ttwa_classification = ifelse(\n\t\ttown11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"), \n\t\t\"Majority conurbation\", ttwa_classification)) %>%\n\tmutate(ttwa11nm = ifelse(\n\t\ttown11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"), \"London\", ttwa11nm)) %>%\n\tmutate(ttwa11cd = ifelse(\n\t\ttown11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"), \"E30000234\", ttwa11cd)) %>%\n\tmutate(across(26:29, ~ifelse(is.na(.),0,.))) %>%\n\tmutate(level_sum = rowSums(.[c(26:29)])) %>%\n\t# to get the number of students in the achievement groups we need to multiply the cohort\n\t# by the percentage and divide by 100 as in the original data they were displayed as \n\t# full numbers, eg 17.2 instead of 0.172.\n\tmutate(highest_level_qualification_achieved_by_age_22_na = 100 - level_sum) %>%\n\tmutate(n_lesslev1_age22 =\n\t\t\tround(highest_level_qualification_achieved_by_age_22_less_than_level_1 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev1to2_age22 =\n\t\t\tround(highest_level_qualification_achieved_by_age_22_level_1_to_level_2 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev3to5_age22 =\n\t\t\tround(highest_level_qualification_achieved_by_age_22_level_3_to_level_5 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev6plus_age22 =\n\t\t\tround(highest_level_qualification_achieved_by_age_22_level_6_or_above * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev_na_age22 =\n\t\t\tround(highest_level_qualification_achieved_by_age_22_na * (ks4_2012_2013_counts/100) ,0))\n```\n:::\n\n\nOk, so we have data, let's make the chart. It's a horizontal bar chart showing the eudcational attainment at age 22 of a cohort of 15-16 year old students who sat for college qualifying exams (GCSEs) in the 2012-13 school year. Meaning the ending time point here is 2018-19. Attainment is plotted by level and by region. Because the original data is by town, we have to group by region to get what we want.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for making the chart\"}\n# need to create cohort population by region\nukeduc %>%\n\trename(region =rgn11nm ) %>%\n\t# group by regions and create region totals \n\tgroup_by(region) %>%\n\tsummarise(region_cohort = sum(ks4_2012_2013_counts),\n\t\t\t\t\tregion_levless1_age22 = sum(n_lesslev1_age22),\n\t\t\t\t\tregion_lev1to2_age22 = sum(n_lev1to2_age22),\n\t\t\t\t\tregion_lev3to5_age22 = sum(n_lev3to5_age22),\n\t\t\t\t\tregion_lev6plus_age22 = sum(n_lev6plus_age22),\n\t\t\t\t\tregion_lev_na_age22 = sum(n_lev_na_age22)) %>%\n\t# pivot longer and make the education attainment field into factors. \n\t# factor labels for the chart\n\tpivot_longer(cols = ends_with(\"age22\"), \n\t\t\t\t\t\tnames_to = \"ed_ettain_age22\", \n\t\t\t\t\t\tvalues_to = \"ed_attain_n\") %>%\n\tmutate(\n\t\ted_ettain_age22 = \n\t\t\tfactor(ed_ettain_age22, \n\t\t\t\t\tlevels = c(\"region_lev_na_age22\", \"region_levless1_age22\", \"region_lev1to2_age22\", \n\t\t\t\t\t\t\t\"region_lev3to5_age22\",  \"region_lev6plus_age22\"), \n\t\t\t\t\tlabels = c(\"No data\", \"Level <1\", \"Level = 1-2\", \"Level = 3-5\", \"Level = 6+\"))) %>%\n\tmutate(ed_attain_pct = ed_attain_n / region_cohort) %>%\n\tmutate(ed_attain_pct2 = round(ed_attain_pct*100, 1)) %>%\n\tungroup() %>%\n\tmutate(region = factor(region)) %>%\n\tfilter(!is.na(region)) %>%\n\t# pass this temporary set thru to the ggplot call\n\t{. ->> tmp} %>%\n\tggplot(aes(ed_attain_pct, fct_rev(region), fill = fct_rev(ed_ettain_age22))) +\n\tgeom_bar(stat = \"identity\") +\n\tscale_x_continuous(\n\t\texpand = c(0,0), \n\t\tbreaks = c(0, 0.25, 0.50, 0.75, 1), \n\t\tlabels = c(\"0\", \"25%\", \"50%\", \"75%\", \"100%\")) +\n\tgeom_text(data = subset(tmp, ed_attain_pct >0.025),\n\t\taes(label = scales::percent(round(ed_attain_pct , 2))),\n\t\t\t\t\tposition = position_stack(vjust = 0.5),\n\t\t\t\t\tcolor= \"white\", vjust = 0.5, size = 5) +\n\tlabs(title = \"Students in London most likely to have at least 4-year degree by Age 22\",\n\t\tsubtitle = \"Sixth Year Educational Outcomes for Level 4 2012-13 Cohort by UK Region\",\n\t\tcaption = \"*Tidy Tuesday data 01/23/2024, from UK Office of National Statistics*\",\n\t\tx = \"\", y = \"Region\") +\n\tscale_fill_brewer(palette = \"Set2\") +\n\ttheme_minimal() +\n\ttheme(legend.position = \"bottom\", legend.spacing.x = unit(0, 'cm'), \n\t\t\tlegend.key.width = unit(1.5, 'cm'), legend.margin=margin(-10, 0, 0, 0),\n\t\t\tplot.title = element_text(hjust = 1), \n\t\t\tplot.caption = element_markdown(),\n\t\t\tpanel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n\tguides(fill = guide_legend(\n\t\tlabel.position = \"bottom\", reverse = TRUE, \n\t\ttitle = \"Cohort at Age 22\", title.position = \"top\"))\n```\n\n::: {.cell-output-display}\n![](images/prompt1_2-1.png){width=100%}\n:::\n:::\n\n\nWe see from this chart that most in regions the rate of 4-year college degree completion (level 6+) was in the mid-high 20s, with students from the London region having the highest rate at 36%.\n\n\n::: {.cell}\n\n:::\n\n\n*created and posted April 21, 2024*\n\n## Prompt #2 - Neo {#prompt2}\n\nThe way I chose to interpret \"neo\" was by using births by country, or new people by country. The data come from [EuroStat](https://ec.europa.eu/eurostat), via the [`eurostat`](https://github.com/rOpenGov/eurostat) package. I'll use total live births and births per 1000 people for the year 2022 (most recent year available). I'll use [`patchwork`](https://patchwork.data-imaginist.com/) to combine the plots. Unlike prompt 1, this only took a little more than an hour to do.\n\nGetting the data is super simple, and it doesn't need much cleaning, so I'll do all the code in one chunk.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting data and making the plots\"}\n# to know the table code \"tps00204\", I had to look up the dataset on-line and copy that value.\n# there is a function in the package to list all available data.\nbirths <- eurostat::get_eurostat(\"tps00204\", type = \"label\", time_format = \"num\") %>%\n\tselect(-freq) %>%\n\trename(year = TIME_PERIOD)\n#> \nindexed 0B in  0s, 0B/s\nindexed 1.00TB in  0s, 1.67PB/s\n                                                                              \n\n# make the plots\ntotal_births <-\nbirths %>%\n\tfilter(year == 2022) %>%\n\tfilter(indic_de == \"Live births - number\") %>%\n\tfilter(!grepl(\"Euro\",geo)) %>%\n\tarrange(desc(values), geo) %>%\n\tmutate(geo = forcats::fct_inorder(geo)) %>%\n\t{. ->> tmp} %>%\n\tggplot(aes(values, fct_rev(geo))) +\n\tgeom_bar(stat = \"identity\", fill = \"#FFCC00\") +\n\tscale_y_discrete(position = \"right\") +\n\t# need to subset data to get highest label to align similar to the rest\n\tgeom_text(data = subset(tmp, values <800000),\n\t\taes(label = format(values, big.mark=\",\")),\n\t\t\t\t\t\tcolor= \"#003399\", size = 4,\n\t\t\t\t\t\thjust = -.25, nudge_x = .25) +\n\tgeom_text(data = subset(tmp, values >800000),\n\t\t\t\t\t\taes(label = format(values, big.mark = \",\")),\n\t\t\t\t\t\tcolor= \"#003399\", size = 4,\n\t\t\t\t\t\thjust = 1, nudge_x = .5) +\n\tlabs(y = \"\", x = \"Total Live Births - 2022\") +\n\ttheme_minimal() +\n\ttheme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\nbirths_per1k <-\nbirths %>%\n\tfilter(year == 2022) %>%\n\tfilter(indic_de == \"Crude birth rate - per thousand persons\") %>%\n\tfilter(!grepl(\"Euro\",geo)) %>%\n\tarrange(desc(values), geo) %>%\n\tmutate(geo = forcats::fct_inorder(geo)) %>%\n\tggplot(aes(values, fct_rev(geo))) +\n\tgeom_bar(stat = \"identity\", fill = \"#003399\") +\n\tgeom_text(aes(label = values),\n\t\t\t\t\t\tposition = position_stack(vjust = 0.5),\n\t\t\t\t\t\tcolor= \"#FFCC00\", vjust = 0.5, size = 4) +\n\tlabs(y = \"\", x = \"Births per 1000 persons - 2022\") +\n\ttheme_minimal() +\n\ttheme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n\n# put them together with patchwork\nlibrary(patchwork)\ntotal_births + births_per1k + plot_annotation(\n\ttitle = 'Turkey tops in both total births and births / 1000 people',\n\tsubtitle = 'France only other country top 10 in both measures. San Marino bottom in both',\n\tcaption = 'Data from EuroStats using eurostat package')\n```\n\n::: {.cell-output-display}\n![](images/prompt2-1.png){width=100%}\n:::\n:::\n\n\nThere you have it. Turkey is tops in both total number of births and births per 1000 people. France is the only other country in the top 10. Interestingly, Spain is near the top in total number (it's a big country) but towards the bottom in births per 1000. San Marino is last in both total births and rate.\n\nWhat other interesting insights do you see here?\n\n\n::: {.cell}\n\n:::\n\n\n*created and posted April 22, 2024*\n\n## Prompts #3 & 4 - Redo & Waffle {#prompts3and4}\n\nFor this prompt I fulfilled prompt 3 \"redo\" by redoing the chart for prompt 1, and made it a waffle chart to fulfill prompt 4. I'd never done a waffle chart before, so new chart type...hooray! Cheers to Yann Holtz for his [code-through](https://r-graph-gallery.com/web-waffle-for-time-evolution.html) on his \"R Graph Gallery\" website to help me better understand how to set-up the data and plot it.\n\nI'm once again using educational attainment data from the UK, via a Tidy Tuesday set from January 2024. We'll get the data and make the chart in the same code chunk.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting data and making the plots\"}\nlibrary(tidyverse) # to do tidyverse things\nlibrary(tidylog) # to get a log of what's happening to the data\nlibrary(janitor) # tools for data cleaning\nlibrary(tidytuesdayR) #to get data from tidy tuesday repo\n\n# some custom functions\nsource(\"~/Data/r/basic functions.R\")\n\n## ggplot helpers - load if necessary\nlibrary(waffle) # ggplot helper to make a waffle chart\nlibrary(ggtext) # helper functions for ggplot text\n\n# load tidy tuesday data\nukeduc1 <- tt_load(\"2024-01-23\")\n#> \n#> \tDownloading file 1 of 1: `english_education.csv`\n\n# get variable names\nukeduc_names <- as_tibble(names(ukeduc1$english_education))\n\n# create tibble from csv, clean data\nukeduc <- as_tibble(ukeduc1$english_education) %>%\n\tmutate(town11nm = ifelse(town11nm == \"Outer london BUAs\", \"Outer London BUAs\", town11nm)) %>%\n\tmutate(\n\t\tttwa_classification = ifelse(town11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Majority conurbation\", ttwa_classification)) %>%\n\tmutate(ttwa11nm = ifelse(town11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t \"London\", ttwa11nm)) %>%\n\tmutate(ttwa11cd = ifelse(town11nm %in% c(\"Inner London BUAs\", \"Outer London BUAs\"),\n\t\t\t\t\t\t\t\t\t\t\t\t\t \"E30000234\", ttwa11cd)) %>%\n\tmutate(across(26:29, ~ifelse(is.na(.),0,.))) %>%\n\tmutate(level_sum = rowSums(.[c(26:29)])) %>%\n\tmutate(highest_level_qualification_achieved_by_age_22_na = 100 - level_sum) %>%\n\tmutate(n_lesslev1_age22 =\n\t\t\t\t \tround(highest_level_qualification_achieved_by_age_22_less_than_level_1 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev1to2_age22 =\n\t\t\t\t \tround(highest_level_qualification_achieved_by_age_22_level_1_to_level_2 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev3to5_age22 =\n\t\t\t\t \tround(highest_level_qualification_achieved_by_age_22_level_3_to_level_5 * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev6plus_age22 =\n\t\t\t\t \tround(highest_level_qualification_achieved_by_age_22_level_6_or_above * (ks4_2012_2013_counts/100) ,0)) %>%\n\tmutate(n_lev_na_age22 =\n\t\t\t\t \tround(highest_level_qualification_achieved_by_age_22_na * (ks4_2012_2013_counts/100) ,0))\n\nglimpse(ukeduc)\n#> Rows: 1,104\n#> Columns: 38\n#> $ town11cd                                                          <chr> \"E34…\n#> $ town11nm                                                          <chr> \"Car…\n#> $ population_2011                                                   <dbl> 5456…\n#> $ size_flag                                                         <chr> \"Sma…\n#> $ rgn11nm                                                           <chr> \"Eas…\n#> $ coastal                                                           <chr> \"Non…\n#> $ coastal_detailed                                                  <chr> \"Sma…\n#> $ ttwa11cd                                                          <chr> \"E30…\n#> $ ttwa11nm                                                          <chr> \"Wor…\n#> $ ttwa_classification                                               <chr> \"Maj…\n#> $ job_density_flag                                                  <chr> \"Res…\n#> $ income_flag                                                       <chr> \"Hig…\n#> $ university_flag                                                   <chr> \"No …\n#> $ level4qual_residents35_64_2011                                    <chr> \"Low…\n#> $ ks4_2012_2013_counts                                              <dbl> 65, …\n#> $ key_stage_2_attainment_school_year_2007_to_2008                   <dbl> 65.0…\n#> $ key_stage_4_attainment_school_year_2012_to_2013                   <dbl> 70.7…\n#> $ level_2_at_age_18                                                 <dbl> 72.3…\n#> $ level_3_at_age_18                                                 <dbl> 50.7…\n#> $ activity_at_age_19_full_time_higher_education                     <dbl> 30.7…\n#> $ activity_at_age_19_sustained_further_education                    <dbl> 21.5…\n#> $ activity_at_age_19_appprenticeships                               <dbl> NA, …\n#> $ activity_at_age_19_employment_with_earnings_above_0               <dbl> 52.3…\n#> $ activity_at_age_19_employment_with_earnings_above_10_000          <dbl> 36.9…\n#> $ activity_at_age_19_out_of_work                                    <dbl> NA, …\n#> $ highest_level_qualification_achieved_by_age_22_less_than_level_1  <dbl> 0.0,…\n#> $ highest_level_qualification_achieved_by_age_22_level_1_to_level_2 <dbl> 34.9…\n#> $ highest_level_qualification_achieved_by_age_22_level_3_to_level_5 <dbl> 39.7…\n#> $ highest_level_qualification_achieved_by_age_22_level_6_or_above   <dbl> 0.0,…\n#> $ highest_level_qualification_achieved_b_age_22_average_score       <dbl> 3.32…\n#> $ education_score                                                   <dbl> -0.5…\n#> $ level_sum                                                         <dbl> 74.6…\n#> $ highest_level_qualification_achieved_by_age_22_na                 <dbl> 25.4…\n#> $ n_lesslev1_age22                                                  <dbl> 0, 0…\n#> $ n_lev1to2_age22                                                   <dbl> 23, …\n#> $ n_lev3to5_age22                                                   <dbl> 26, …\n#> $ n_lev6plus_age22                                                  <dbl> 0, 8…\n#> $ n_lev_na_age22                                                    <dbl> 17, …\n\n# cohort ed attainment by region\nukeduc2 <-\n\tukeduc %>%\n\trename(region =rgn11nm ) %>%\n\tgroup_by(region) %>%\n\tsummarise(region_cohort = sum(ks4_2012_2013_counts),\n\t\t\t\t\t\tregion_levless1_age22 = sum(n_lesslev1_age22),\n\t\t\t\t\t\tregion_lev1to2_age22 = sum(n_lev1to2_age22),\n\t\t\t\t\t\tregion_lev3to5_age22 = sum(n_lev3to5_age22),\n\t\t\t\t\t\tregion_lev6plus_age22 = sum(n_lev6plus_age22)) %>%\n\tpivot_longer(cols = ends_with(\"age22\"), names_to = \"ed_attain_age22\", values_to = \"ed_attain_n\") %>%\n\tmutate(ed_attain_pct = ed_attain_n / region_cohort) %>%\n\tmutate(ed_attain_pct2 = round(ed_attain_pct*100)) %>%\n\tmutate(region = factor(region))%>%\n\tfilter(!is.na(region)) %>%\n\tselect(region, region_cohort, ed_attain_age22, ed_attain_pct2) %>%\n\t## the data was a bit messy, so to get the values to sum to 100 to make the waffle\n\t## chart fill the plot area, I had to do a little reshaping after doing the percentages.\n\tpivot_wider(names_from = ed_attain_age22, values_from = ed_attain_pct2) %>%\n\tmutate(region_sum = rowSums(.[c(3:6)])) %>%\n\tmutate(region_lev_na_age22 = ifelse(region_sum < 100, 100 - region_sum, 0)) %>%\n\tselect(-region_sum) %>%\n\tpivot_longer(cols = ends_with(\"age22\"), names_to = \"ed_attain_age22\", values_to = \"ed_attain_pct\") %>%\n\tmutate(ed_attain_age22 =\n\t\t\t \tfactor(ed_attain_age22,\n\t\t\t \t\t\t\t levels = c(\"region_lev_na_age22\", \"region_levless1_age22\", \"region_lev1to2_age22\",\n\t\t\t \t\t\t\t \t\t\t\t\t \"region_lev3to5_age22\", \"region_lev6plus_age22\"),\n\t\t\t \t\t\t\t labels = c(\"No data\", \"Level <1\", \"Level = 1-2\",\n\t\t\t \t\t\t\t \t\t\t\t\t \"Level = 3-5\", \"Level = 6+\")))\nglimpse(ukeduc2)\n#> Rows: 45\n#> Columns: 4\n#> $ region          <fct> East Midlands, East Midlands, East Midlands, East Midl…\n#> $ region_cohort   <dbl> 39811, 39811, 39811, 39811, 39811, 48849, 48849, 48849…\n#> $ ed_attain_age22 <fct> Level <1, Level = 1-2, Level = 3-5, Level = 6+, No dat…\n#> $ ed_attain_pct   <dbl> 2, 30, 41, 25, 2, 2, 27, 43, 27, 1, 2, 19, 43, 36, 0, …\n\n## chart\nukeduc2\t%>%\n\tggplot(aes(fill = ed_attain_age22, values = ed_attain_pct)) +\n\tgeom_waffle(na.rm=TRUE, n_rows=10, flip=TRUE, size = 0.33, colour = \"white\") +\n\tfacet_wrap(~region, nrow=1,strip.position = \"bottom\") +\n\tscale_x_discrete() +\n\tscale_y_continuous(labels = function(x) x * 10, # make this multiplyer the same as n_rows\n\t\t\t\t\t\t\t\t\t\t expand = c(0,0)) +\n\tscale_fill_brewer(palette = \"Set2\") +\n\t\tlabs(title = \"Students in London most likely to have at least 4-year degree by Age 22\",\n\t\t\t\t subtitle = \"Sixth Year Educational Outcomes for Level 4 2012-13 Cohort by UK Region<br>\n\t\t\t\t Each block = 1 %\",\n\t\t\t\t caption = \"*Tidy Tuesday data 01/23/2024, from UK Office of National Statistics*\",\n\t\t\t\t x = \"\", y = \"\") +\n\ttheme_minimal() +\n\t\ttheme(legend.position = \"bottom\", legend.spacing.x = unit(0, 'cm'),\n\t\t\t\t\tlegend.key.width = unit(1.5, 'cm'), legend.margin=margin(-10, 0, 0, 0),\n\t\t\t\t\tplot.title = element_text(hjust = 0), plot.subtitle = element_markdown(),\n\t\t\t\t\tplot.caption = element_markdown(),\n\t\t\t\t\tpanel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n\tguides(fill = guide_legend(label.position = \"bottom\", \n\t\t\t\t\t\t\t\t\t\t\ttitle = \"Cohort at Age 22\", \n\t\t\t\t\t\t\t\t\t\t\ttitle.position = \"top\"))\n```\n\n::: {.cell-output-display}\n![](images/prompt3&4-1.png){width=100%}\n:::\n:::\n\n\nSo alright, a waffle chart. Similar insights from the horizontal bar, just visualized a bit differently.\n\n*created and posted April 23, 2024*\n\n## Prompt #5 - Diverging {#prompt5}\n\nStaying with the theme of educational attainment, but switching countries to Denmark (where I was born and now live again), let's look at differences in educational attainment for people in Denmark aged 25-69. The data come from Danmarks Statistik (Statistics Danmark, the national statistics agency) via the [`danstat`](https://github.com/ValeriVoev/danstat) package. I've been wanting to use the package, this was a great excuse.\n\nI won't do too much explaining about education levels in Denmark, you can read up on them on the [ministry's page](https://ufm.dk/en/education/the-danish-education-system).\n\nThe `danstat` package is fairly easy to use once you get the hang of sorting out the table name and number, and variable names and values you need to filter on. It's a good idea to start at Danmarks Statistik's [StatBank page](https://www.statbank.dk/statbank5a/default.asp?w=1680), search the data you want, and when you find the table, you'll see the code, in this case HFUDD11, and use that in the package calls. To see what I mean, let's start with getting the data.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting data\"}\nlibrary(tidyverse) # to do tidyverse things\nlibrary(tidylog) # to get a log of what's happening to the data\nlibrary(janitor) # tools for data cleaning\nlibrary(danstat) # package to get Danish statistics via api\nlibrary(ggtext) # enhancements for text in ggplot\n\n# some custom functions\nsource(\"~/Data/r/basic functions.R\")\n\n\n# metadata for table variables, click thru nested tables to find variables and ids for filters\ntable_meta <- danstat::get_table_metadata(table_id = \"hfudd11\", variables_only = TRUE)\n\n# create variable list using the ID value in the variable\nvariables_ed <- list(\n\tlist(code = \"bopomr\", values = \"000\"),\n\tlist(code = \"hfudd\", values = c(\"H10\", \"H20\", \"H30\", \"H35\",\n\t\t\t\t\t\t\t\t\t\t\"H40\", \"H50\", \"H60\", \"H70\", \"H80\", \"H90\")),\n\tlist(code = \"køn\", values = c(\"M\",\"K\")),\n\tlist(code = \"alder\", values = c(\"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"50-54\", \"55-59\", \"60-64\", \"65-69\")),\n\tlist(code = \"tid\", values = 2023))\n\n# past variable list along with table name. \n# note that in package, table name is lower case, though upper case on statbank page.\nedattain <- get_data(\"hfudd11\", variables_ed, language = \"da\") %>%\n\tas_tibble() %>%\n\tselect(sex = KØN, age = ALDER, edlevel = HFUDD, n = INDHOLD)\n```\n:::\n\n\nThe data I pulled is by sex, age, and education level. I needed to age variable to filter for age 25+, as the set starts at age 15. At some point for another post I plan to look a bit more deeply at educational attainment here, including region and age and other fields. So let's clean the data and get it ready to plot a diverging bar chart.\n\nEven though I've calculated percentages for sex by age by education level, I won't be doing any breakdowns by age here, again, that's a later independent post. But at least I have the code now.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for cleaning data\"}\nedattain1 <- edattain %>%\n\t## create factors from the education levels\n\tmutate(edlevel =\n\t\tfactor(edlevel,\n\t\t\tlevels = c(\"H10 Grundskole\", \"H20 Gymnasiale uddannelser\",\n\t\t\t\"H30 Erhvervsfaglige uddannelser\", \"H35 Adgangsgivende uddannelsesforløb\",\n\t\t\t\"H40 Korte videregående uddannelser, KVU\", \"H50 Mellemlange videregående uddannelser, MVU\",\n\t\t\t\"H60 Bacheloruddannelser, BACH\", \"H70 Lange videregående uddannelser, LVU\",\n\t\t\t\"H80 Ph.d. og forskeruddannelser\", \"H90 Uoplyst mv.\"),\n\t\t\tlabels = c(\"Grundskole/Primary\", \"Gymnasium\",\n\t\t\t\"Erhvervsfaglige/Vocational HS\", \"Adgangsgivende/Qualifying\",\n\t\t\t\"KVU/2-year college\", \"MVU/Professional BA\",\n\t\t\t\"Bachelor\", \"LVU/Masters\", \"PhD\", \"Not stated\" ))) %>%\n\tmutate(sex = ifelse(sex == \"Kvinder\", \"Kvinder/Women\", \"Mænd/Men\")) %>%\n\t# calculate total number by sex\n\tarrange(sex, edlevel) %>%\n\tgroup_by(sex) %>%\n\tmutate(tot_sex = sum(n)) %>%\n\tungroup() %>%\n\t# calculate total number by sex and ed level\n\tgroup_by(sex, edlevel) %>%\n\tmutate(tot_sex_edlev = sum(n)) %>%\n\tungroup() %>%\n\t# calculate total number by sex and age\n\tgroup_by(sex, age) %>%\n\tmutate(tot_sex_age = sum(n)) %>%\n\tungroup() %>%\n\t# calculate percentages \n\tmutate(level_pct = round(tot_sex_edlev / tot_sex, 3)) %>%\n\tmutate(level_pct = ifelse(sex == \"Mænd/Men\", level_pct *-1, level_pct)) %>%\n\tmutate(level_pct2 = round(level_pct * 100, 1)) %>%\n\tmutate(age_level_pct = round(n / tot_sex_age, 3)) %>%\n\tmutate(age_level_pct = ifelse(sex == \"Mænd/Men\", age_level_pct *-1, age_level_pct)) %>%\n\tmutate(age_level_pct2 = round(age_level_pct * 100, 1))\n```\n:::\n\n\nNow let's make the plot.\n\n\n::: {.cell ECHO='true'}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for making the plot\"}\nvlines_df <- data.frame(xintercept = seq(-100, 100, 20))\n\nedattain1 %>%\n\tfilter(!edlevel == \"Not stated\") %>%\n\tdistinct(sex, edlevel, .keep_all = TRUE) %>%\n\tselect(sex, edlevel:tot_sex, level_pct, level_pct2 ) %>%\n\t# pass this temporary set thru to the ggplot call\n\t{. ->> tmp} %>%\n\tggplot() +\n\tgeom_col(aes(x = -50, y = edlevel), width = 0.75, fill = \"#e0e0e0\") +\n\tgeom_col(aes(x = 50, y = edlevel), width = 0.75, fill = \"#e0e0e0\") +\n\tgeom_col(aes(x = level_pct2, y = edlevel, fill = sex, color = sex), width = 0.75) +\n\tscale_x_continuous(labels = function(x) abs(x), breaks = seq(-100, 100, 20)) +\n\tgeom_vline(data = vlines_df, aes(xintercept = xintercept), color = \"#FFFFFF\", size = 0.1, alpha = 0.5) +\n\tcoord_cartesian(clip = \"off\") +\n\tscale_fill_manual(values = c(\"#C8102E\", \"#FFFFFF\")) +\n\tscale_color_manual(values = c(\"#C8102E\", \"#C8102E\")) +\n\tgeom_text(data = subset(tmp, sex == \"Mænd/Men\"),\n\t\t\t\taes(x = level_pct2, y = edlevel, label = paste0(abs(level_pct2), \"%\")),\n\t\t\t\tsize = 5, color = \"#C8102E\",\n\t\t\t\thjust = 1, nudge_x = -.5) +\n\tgeom_text(data = subset(tmp, sex == \"Kvinder/Women\"),\n\t\t\t\taes(x = level_pct2, y = edlevel, label = paste0(abs(level_pct2), \"%\")),\n\t\t\t\tsize = 5, color = \"#C8102E\",\n\t\t\t\thjust = -.25) +\n\tlabs(x = \"\", y = \"\",\n\t\t\t title = \"In Denmark, <span style = 'color: #C8102E;'>women</span> more likely than men for highest education\n\t\t\t level to be <br>Professional BA (MVU) or Masters.<br><br>Men more likely to stop at primary level or vocational secondary diploma.\",\n\t\t\t subtitle = \"<br>*Highest level of education attained by all people in Denmark aged 25-69 as of Sept 30 2023.\n\t\t\t <br><span style = 'color: #C8102E;'>Women are red bars</span>, men are white.*\",\n\t\t\t caption = \"*Data from Danmarks Statistik via danstat package*\") +\n\ttheme_minimal() +\n\ttheme(panel.grid = element_blank(), plot.title = element_markdown(),\n\t\t\t\tplot.subtitle = element_markdown(), plot.caption = element_markdown(),\n\t\t\t\tlegend.position = \"none\",\n\t\t\t\taxis.text.y = element_text(size = 10))\n```\n\n::: {.cell-output-display}\n![](images/prompt5_3-1.png){width=100%}\n:::\n:::\n\n\nThere it is, a simple, clean chart showing how highest educational attainment differs for women and men in Denmark. I'm definitely interested in exploring differences by age group and by region.\n\n\n::: {.cell}\n\n:::\n\n\n*created and posted April 24, 2024*\n\n## Prompt #6 - OECD {#prompt6}\n\nStaying with the emerging theme of educational attainment, this prompt was a good excuse to try out the [`oecd` package](https://github.com/expersso/OECD). The package wraps functions to access OECD data through their API for their [Data Explorer platform](https://data-explorer.oecd.org/).\n\nIt's fairly straight forward to use...look up the table you want, set the filters, copy the API script and parse out as the package documentation shows. In the example they do not show it, but make sure if you set time parameters that you put it in the `start_date` and `end_date` calls. You can of course name the dataset and filters anything you want. I chose my names so they wouldn't conflict with function calls.\n\nFor this chart I looked at educational attainment in Nordic countries; Denmark, Finland, Iceland, Norway, & Sweden *(i)*, by sex for all people aged 25 to 64 in 2022. For the sake of expediency, I'll copy the overall format & theme from prompt 1.\n\n*i) let's not get into here the difference between Nordic & Scandinavian, what constitutes Scandinavian & why...*\n\nThe code for getting the data and making the chart is below.\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for prompt 6\"}\n## code for 30 Day Chart Challenge 2024, day 6 OECD\n## educational attainment via OECD package\n## nordics, by sex 25 to 64, 2020-2022\n\nlibrary(tidyverse) # to do tidyverse things\nlibrary(tidylog) # to get a log of what's happening to the data\nlibrary(janitor) # tools for data cleaning\nlibrary(OECD) # package to get OECD data via api\nlibrary(ggtext) # enhancements for text in ggplot\n\n# table from website\n# https://www.oecd-ilibrary.org/education/data/education-at-a-glance/educational-attainment-and-labour-force-status_889e8641-en\n\nedattdata <- \"OECD.CFE.EDS,DSD_REG_EDU@DF_ATTAIN,1.0\"\nedattfilter <- \"A.CTRY.SWE+NOR+ISL+FIN+DNK...Y25T64.F+M.ISCED11_0T2+ISCED11_5T8+ISCED11_3_4..\"\n\noecd1 <- get_dataset(edattdata, edattfilter, start_time = 2020, end_time = 2022)\n\n# get metadata - helpful to create labels for factors.\n# see package documentation on github \n# commented out here to speed up rendering of post html file...this takes a while to download\n   # oecd_metadata <- get_data_structure(edattdata)\n\n# gets labels for country codes...this step commented out, data loading from local file.\n# datalabs_ct <- oecd_metadata$CL_REGIONAL %>%\n# \trename(COUNTRY = id)\n\ndatalabs_ct <- readRDS(\"~/Data/r/30 Day Chart Challenge/2024/data/oecd_datalabs_ct.rds\") \n\n# keep only necessary vars, change some to factors & add labels\noecd <- oecd1 %>%\n\tmutate(EDUCATION_LEV =\n\t\tfactor(EDUCATION_LEV,\n\t\t\tlevels = c(\"ISCED11_0T2\", \"ISCED11_3_4\", \"ISCED11_5T8\"),\n\t\t\tlabels = c(\"Pre-primary thru lower secondary\",\n\t\t\t\t \t\t\"Upper secondary and non-degree tertiary\", \"Tertiary education\"))) %>%\n\tmutate(SEX = case_when(SEX == \"M\" ~ \"Male\", SEX == \"F\" ~ \"Female\")) %>%\n\tmutate(pct_attain2 = as.numeric(ObsValue)) %>%\n\tmutate(pct_attain = pct_attain2 / 100) %>%\n\t# join to have labels instead of country abbrvs\n\tleft_join(datalabs_ct) %>%\n\tselect(country = label,  year = TIME_PERIOD, SEX, EDUCATION_LEV, pct_attain, pct_attain2) %>%\n\tclean_names()\n\n## chart...horizontal stacked bar\noecd %>%\n\tfilter(year == \"2022\") %>%\n\tggplot(aes(pct_attain, fct_rev(country), fill = fct_rev(education_lev))) +\n\tgeom_bar(stat = \"identity\") +\n\tscale_x_continuous(expand = c(0,0),\n\t\t\t\tbreaks = c(.01, 0.25, 0.50, 0.75, .97),\n\t\t\t\tlabels = c(\"0\", \"25%\", \"50%\", \"75%\", \"100%\")) +\n\tfacet_wrap(~ sex, nrow = 1) +\n\tgeom_text(aes(label = scales::percent(round(pct_attain , 2))),\n\t\t\t\tposition = position_stack(vjust = 0.5),\n\t\t\t\tcolor= \"white\", vjust = 0.5, size = 5) +\n\tlabs(title = \"In Nordic countries, women age 25-64 more likely than men to complete college.<br><br>\n\t\t\t Finns have lowest levels of attainment stopping at lower secondary\",\n\t\t\t subtitle = \"<br>*Educational Attainment in Nordic Countries, by Sex, ages 25-64 combined, 2022*\",\n\t\t\t caption = \"*Data from OECD, via oecd package for r*\",\n\t\t\t x = \"\", y = \"\") +\n\tscale_fill_brewer(palette = \"Set2\") +\n\ttheme_minimal() +\n\ttheme(legend.position = \"bottom\", legend.spacing.x = unit(0, 'cm'),\n\t\t\t\tlegend.key.width = unit(1.5, 'cm'), legend.margin=margin(-10, 0, 0, 0),\n\t\t\t\tplot.title = element_markdown(), plot.subtitle = element_markdown(),\n\t\t\t\tplot.caption = element_markdown(),\n\t\t\t\taxis.text.y = element_text(size = 12),\n\t\t\t\tpanel.grid.major = element_blank(), panel.grid.minor = element_blank()) +\n\tguides(fill = guide_legend(label.position = \"bottom\", reverse = TRUE,\n\t\t\t\ttitle = \"Education Levels\", title.position = \"top\"))\n```\n\n::: {.cell-output-display}\n![](images/prompt6-1.png){width=100%}\n:::\n:::\n\n\nYou can see that there are some differences in levels of attainment between countries. I don't know enough context to speculate as to why. Also, as you add more countries to the filter, the education levels and age groups are aggregated into bigger buckets, presumably to facilitate comparisons. Denmark has a good national database where you can drill down more by age and level, so if I wanted to look at differences by smaller age groups and over time, I'd have to dig into the individual countries national statistics databanks and would have to hope that the age groups and attainment levels are similar enough.\n\n*created and posted April 26, 2024*\n\n## Prompt #7 - Hazards {#prompt7}\n\nHazards is vague enough to mean anything, and if you search the socials for maps submitted for this prompt you'll see a variety of approaches. Right away I thought of crime stats, and also right away I knew I wanted to make a map of crime data in Denmark.\n\nSo that's what I set out to do.\n\nBut very soon into building it I realized I wanted to visualise different types of crime, which meant multiple plots. So then I got it in my head that this should be an exercise in really getting comfortable with functional programming and iterating using `map()` or a similar approach.\n\nSo that's what I did.\n\nFollow along now as we get data, build a plot function, map over it, and make some maps.\n\nFirst, the data. As with the [diverging challenge](https://www.gregdubrow.io/posts/30-day-chart-challenge-2024/#prompt5) I got the data from [Danmarks Statistik](https://www.dst.dk/en) (Statistics Danmark, the national statistics agency). Unlike the diverging challenge, I did not end up using the [`danstat`](https://github.com/ValeriVoev/danstat) package.\n\nWhy? Well I wanted to use the [province aggregation](https://en.wikipedia.org/wiki/Provinces_of_Denmark), the middle level between towns and regions. I wanted to see a bit of nuance in the maps. The problem is, while province data can be pulled from the [StatBank data portal](https://www.statbank.dk/) the [API](https://www.dst.dk/en/Statistik/brug-statistikken/muligheder-i-statistikbanken/api#) only has cities, regions, and all of Denmark. So loading flat-files it is.\n\nBut In this first chunk we get the geographic boundary data. For this we'll be using NUTS3 level. What are the NUTS levels? (settle down, Beavis) Well, per the [European Commission and Eurostat](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Nomenclature_of_territorial_units_for_statistics_(NUTS)) they are:\n\n> Blockquote \"The Nomenclature of territorial units for statistics, abbreviated NUTS (from the French version Nomenclature des Unités territoriales statistiques) is a geographical nomenclature subdividing the economic territory of the European Union (EU) into regions at three different levels (NUTS 1, 2 and 3 respectively, moving from larger to smaller territorial units).\n\nIn Denmark NUTS1 is the entire country, NUTS2 are the major regions, and NUTS3 are the provinces. The process for doing this comes from one of the excellent tutorials by [Milos Popvic](https://github.com/milos-agathon/how-i-make-eurostat-maps/blob/main/R/main.r) in his *Milos Makes Maps* series of [video](https://www.youtube.com/@milos-makes-maps/videos) and code how-tos.\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting map boundary data\"}\n# load all the packages we'll need\nlibrary(tidyverse) # to do tidyverse things\nlibrary(sf) # to make our geo data mappable\nlibrary(giscoR) # gets the region level boundries\nlibrary(tidylog) # to get a log of what's happening to the data\nlibrary(janitor) # tools for data cleaning\nlibrary(danstat) # package to get Danish statistics via api\nlibrary(ggtext) # enhancements for text in ggplot\nlibrary(patchwork) # puts plots together\n\nsource(\"~/Data/r/basic functions.R\")\n\n### Get mapping data\n# define longlat projection\ncrsLONGLAT <- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\n# get NUTS3 data for Denmark and use sf to make it plottable\nnuts3_dk <- giscoR::gisco_get_nuts(\n\tyear = \"2021\",\tresolution = \"3\",\n\tnuts_level = \"3\", country = \"DK\") |>\n\trename(province_name = NAME_LATN) |>\n\tsf::st_transform(crsLONGLAT)\n```\n:::\n\n\nNow we add the crime and population data via spreadsheet import, and join it to the map data. The crime data needs a bit of tidying up, shortening the names, some other text edits. We'll normalize crime data by incidents per 100,000 people. Because the crime data come by yearly quarters and I wanted one entire year (adding up the four quarters), I pulled population data for the start of the 3rd quarter of 2023. I figured that was a good representative time-point for the entire year.\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for getting crime and population data\"}\ncrime_2023_1 <- readxl::read_excel(\"~/Data/r/30 Day Chart Challenge/2024/data/dk_crime_by_province_2023.xlsx\") %>%\n\tclean_names() %>%\n\tfill(offence_cat_code) %>%\n\tfill(offence_cat_name) %>%\n\trename_with(~ sub(\"^x\", \"tot_\", .x), starts_with((\"x\"))) %>%\n\tmutate(tot_2023 = rowSums(.[c(5:8)])) %>%\n\tmutate(province_name = str_replace(province_name, \"Province \", \"\")) %>%\n\tmutate(offence_cat_name = str_replace(offence_cat_name, \", total\", \"\")) %>%\n\tmutate(offence_cat_name = str_replace(\n\t\toffence_cat_name, \"Nature of the offence\", \"All offences\")) %>%\n\tmutate(offence_cat_name = str_replace(\n\t\toffence_cat_name, \"Offences against property\", \"Property crime\")) %>%\n\tmutate(offence_cat_name = str_replace(\n\t\toffence_cat_name, \"Crimes of violence\", \"Violent crime\")) %>%\n\tmutate(offence_cat_name =\n\t\t\tfactor(offence_cat_name,\n\t\t\tlevels = c(\"All offences\", \"Criminal code\", \"Sexual offenses\", \"Violent crime\", \"Property crime\",\n\t\t\t\t \t\t\"Other offences\", \"Special acts\"))) %>%\n\tselect(province_name, offence_cat_name, tot_2023)\n\n## get population data to normalize \n# based on total at start of 2023 Q3\npop_2023 <- readxl::read_excel(\"~/Data/r/30 Day Chart Challenge/2024/data/dk_pop_2023_q3.xlsx\") %>%\n\tclean_names() %>%\n\tmutate(province_name = str_replace(province_name, \"Province \", \"\"))\n\n# join crime & population\ncrime_2023_2 <- crime_2023_1 %>%\n\tleft_join(pop_2023) %>%\n\tmutate(crime_per1k = round(tot_2023 / tot_pop * 100000, 0))\n\n## left_join nuts sf object to crime data to get sf object for plot\ncrime_2023 <- nuts3_dk %>%\n\tleft_join(crime_2023_2, by = \"province_name\")\n```\n:::\n\n\nNow that we have a dataset ready to be mapped, it's time to build the plot function. Being fully honest, functional programming and iterating over objects have long been my `r` bugaboos. I have no idea why, but I just couldn't internalize the logic. But putting together the [bicycle rides post](https://www.gregdubrow.io/posts/my-year-of-riding-danishly/) where I employed [Cedric Scherer's tutorial](https://www.cedricscherer.com/2023/07/05/efficiency-and-consistency-automate-subset-graphics-with-ggplot2-and-purrr/) I started to get it.\n\nIt took much longer to trial-and-error a few different approaches and get the text and layout as I wanted than it would have to copy-paste-adjust the plot code seven times and stitch together with `patchwork`, but now I have a map function I can re-use. A small but helpful part of the function is the [`ggsflabel`](https://yutannihilation.github.io/ggsflabel/) package to help offset labels for Copenhagen (Byen København & Københavns omgen).\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for the map function\"}\ndk_crime_map <- function(offence, maptitle) {\n\tg <-\n\t\tggplot() +\n\t\tgeom_sf(data = (crime_2023 %>% filter(offence_cat_name== offence)),\n\t\t\t\t\t\taes(fill = crime_per1k), color = \"#FFFFFF\", size = 3) +\n\t\tgeom_sf_text(data = (crime_2023 %>%\n\t\t\t\t\tfilter(province_name %notin% c(\"Byen København\", \"Københavns omegn\")) %>%\n\t\t\t\t\tfilter(offence_cat_name == \"Special acts\")),\n\t\t\t\t\t\taes(label = province_name), nudge_x = -.5, size = 2)\t+\n\t\tggsflabel::geom_sf_label_repel(data = (crime_2023 %>%\n\t\t\t\t\tfilter(province_name %in% c(\"Byen København\", \"Københavns omegn\")) %>%\n\t\t\t\t\tfilter(offence_cat_name == offence)),\n\t\t\t\t\t\taes(label = province_name), size = 1.5,\n\t\t\t\t\t\tforce = 1, nudge_x = 4, nudge_y = .75) +\n\t\tscale_fill_gradient(trans = \"reverse\") +\n\t\tlabs(x = \"\", y = \"\") +\n\t\ttheme_minimal() +\n\t\tggtitle(maptitle) +\n\t\ttheme(panel.grid = element_blank(),\n\t\t\t\tplot.title = element_text(size = 11, hjust = .6, vjust = -7),\n\t\t\t\taxis.line = element_blank(), axis.ticks = element_blank(),\n\t\t\t\taxis.text.x = element_blank(), axis.text.y = element_blank(),\n\t\t\t\tlegend.position = c(.4, -.2), \n\t\t\t\tlegend.title = element_text(size = 7),\n\t\t\t\tlegend.text = element_text(size = 7)\n\t\t\t\t\t) +\n\t\tguides(fill = guide_legend(\n\t\t\ttitle = \"Incidents per 100K people\",\n\t\t\tdirection = \"horizontal\",\n\t\t\tkeyheight = unit(1, units = \"mm\"),\n\t\t\tkeywidth = unit(10, units = \"mm\"),\n\t\t\ttitle.position = \"top\",\n\t\t\ttitle.hjust = .5,\n\t\t\tlabel.hjust = .5,\n\t\t\tnrow = 1,\n\t\t\tbyrow = T,\n\t\t\treverse = F,\n\t\t\tlabel.position = \"bottom\"\n\t\t))\n\n\treturn(g)\n}\n```\n:::\n\n\nThe function is ready, now we iterate over the seven crime categories and put the plots together in one image. To magnify it for better viewing, click on it to bring it up in a lightbox.\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-scroll  code-fold=\"true\" code-summary=\"Show code for generating the plots\"}\n## map over all crime categories\n# create list of crime types\ncrimecats <- unique(crime_2023_2$offence_cat_name)\n\n# create plots, stitch together with patchwork\nwrap_plots(\n\tmap(crimecats, ~dk_crime_map(offence = .x, maptitle = .x)),\n\twidths = 5, heights = 5) +\n\tplot_annotation(\n\t\ttitle = \"Crimes by Type and Province in Denmark, 2023\",\n\t\tsubtitle = \"*Total Crimes per 100K people*\",\n\t\tcaption = \"*Data from Danmarks Statistik. Criminal code = sexual offences + violence + property + other*\",\n\t\ttheme = theme(plot.subtitle = element_markdown(),\n\t\t\t\t\tplot.caption = element_markdown()))\n```\n\n::: {.cell-output-display}\n![](images/prompt_7_4-1.png){width=100%}\n:::\n:::\n\n\nIf this were for an official company or organization report or academic publication there are some tweaks I'd want to make...the color palette, maybe writing a function to make the breaks better, spacing of province labels, maybe making it interactive with tool tips that show province name along with other data. I might do an inset or separate plots for Copenhagen. But for the purpose of the chart challenge I'm happy with it because it meets my goal, which was to build a plot function and iterate it over a vector, rather than copy-paste and edit the plot code.\n\n*created and posted April 29, 2024*\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}